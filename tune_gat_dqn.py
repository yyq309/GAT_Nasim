import optuna
import nasim
import torch
from nasim.agents.reward_gat_dqn_agent import GATDQNAgent
from statistics import mean

# ==========================
# ğŸ’¡ è°ƒå‚ç›®æ ‡å‡½æ•°
# ==========================
def objective(trial):
    # åˆ›å»º NASim ç¯å¢ƒ
    env = nasim.make_benchmark("medium", fully_obs=True, flat_actions=True, flat_obs=True)
    
    # ==========================
    # ğŸ“¦ å®šä¹‰å¾…æœç´¢å‚æ•°ç©ºé—´
    # ==========================
    lr = trial.suggest_float("lr", 1e-4, 5e-3, log=True)
    gamma = trial.suggest_float("gamma", 0.90, 0.99)
    batch_size = trial.suggest_categorical("batch_size", [32, 64, 128])
    hidden_dim = trial.suggest_int("hidden_dim", 64, 256)
    num_heads = trial.suggest_int("num_heads", 2, 8)
    dropout = trial.suggest_float("dropout", 0.1, 0.5)
    target_update_freq = trial.suggest_int("target_update_freq", 500, 5000)
    exploration_steps = trial.suggest_int("exploration_steps", 5000, 20000)
    final_epsilon = trial.suggest_float("final_epsilon", 0.01, 0.1)

    # ==========================
    # ğŸš€ åˆå§‹åŒ–ä»£ç†
    # ==========================
    agent = GATDQNAgent(
        env=env,
        lr=lr,
        gamma=gamma,
        batch_size=batch_size,
        hidden_sizes=[hidden_dim, hidden_dim],
        num_heads=num_heads,
        dropout=dropout,
        target_update_freq=target_update_freq,
        exploration_steps=exploration_steps,
        final_epsilon=final_epsilon,
        training_steps=100000,
        verbose=False,
        device="cuda" if torch.cuda.is_available() else "cpu"
    )

    # ==========================
    # ğŸ§  è¿è¡Œè®­ç»ƒå¹¶è¿”å›è¯„ä¼°æŒ‡æ ‡
    # ==========================
    try:
        rewards = []
        for _ in range(3):  # æ¯ç»„å‚æ•°è·‘3æ¬¡å–å¹³å‡ï¼Œæé«˜ç¨³å¥æ€§
            agent.train()
            ep_return, _, _ = agent.run_eval_episode(render=False)
            rewards.append(ep_return)
        avg_reward = mean(rewards)
    except Exception as e:
        print(f"[Trial failed] {e}")
        avg_reward = -9999  # å‡ºé”™åˆ™ç»™ä¸ªå¾ˆä½çš„åˆ†

    return avg_reward


# ==========================
# ğŸ å¯åŠ¨Optunaæœç´¢
# ==========================
if __name__ == "__main__":
    study = optuna.create_study(direction="maximize", study_name="GATDQN_Tuning")
    study.optimize(objective, n_trials=30, show_progress_bar=True)

    print("\nâœ… æœ€ä¼˜è¶…å‚æ•°ç»„åˆ:")
    for key, value in study.best_params.items():
        print(f"  {key}: {value}")

    print(f"\nğŸ† å¯¹åº”çš„å¹³å‡reward: {study.best_value:.2f}")

    # ä¿å­˜ç»“æœ
    study.trials_dataframe().to_csv("gat_dqn_tuning_results.csv", index=False)
